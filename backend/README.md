# Backend â€” Inferno

## Setup
- Python 3.10+
- Recommended: use a virtual environment

## Dependencies
- llama-cpp-python
- websockets
- See `requirements.txt` for full list

## Running the Backend
- Activate your virtual environment
- Install dependencies: `pip install -r requirements.txt`
- Start the backend server: `python main.py` (to be implemented)

## Notes
- Only local GGUF models are supported
- See [../docs/architecture.md](../docs/architecture.md) for backend responsibilities 